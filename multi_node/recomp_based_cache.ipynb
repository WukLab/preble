{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from uuid import uuid4\n",
    "import copy\n",
    "import threading\n",
    "import logging\n",
    "from benchmarks.benchmark_utils import RequestFuncOutput\n",
    "\n",
    "logging = logging.getLogger(__name__)\n",
    "DEBUG_COUNTER = 0\n",
    "class LpNode:\n",
    "    def __init__(self, node_id, num_gpus):\n",
    "        self.node_id = node_id\n",
    "        self.variables = [\n",
    "            None for _ in range(num_gpus)\n",
    "        ]  # Will be initialized as binary variables in the model\n",
    "        self.children_token_cost_at_max_depth = 0  # Issue is that depth_limit will cut off the tokens for children and that will treat it as free\n",
    "        self.randomly_selected_gpu = None\n",
    "        self.load_variables = [None for _ in range(num_gpus)]\n",
    "        self.common_load = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        variable_values = [var.x if var else None for var in self.variables]\n",
    "        load_variable_values = [var.x if var else None for var in self.load_variables]\n",
    "        common_load = self.common_load.x if self.common_load else None\n",
    "        # ignore printing laod variables if None\n",
    "        if any(load_variable_values):\n",
    "            return f\"LpNode(node_id={self.node_id}, variables={variable_values}, load_variables={load_variable_values}, common_load={common_load})\"\n",
    "        else:\n",
    "            return f\"LpNode(node_id={self.node_id}, variables={variable_values})\"\n",
    "\n",
    "\n",
    "class LPTreeNode:\n",
    "    def __init__(self):\n",
    "        self.id = uuid4()\n",
    "        self.children = defaultdict(LPTreeNode)\n",
    "        self.parent: Optional[LPTreeNode] = None\n",
    "        self.value = None\n",
    "        self.ref_counter = 0\n",
    "        self.last_access_time = time.time()\n",
    "        self.gpu_selections = set()\n",
    "        self.is_leaf = False\n",
    "        self.decode_length = 0\n",
    "        self.context_length = 0\n",
    "\n",
    "    @property\n",
    "    def num_tokens(self):\n",
    "        return len(self.value)\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.last_access_time < other.last_access_time\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, LPTreeNode):\n",
    "            return self.id == other.id  # Compare nodes based on their unique ID\n",
    "        return False\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.id)  # Use the unique ID for hashing\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"LPTreeNode(id={self.id}, ref_counter={self.ref_counter}, gpu_selections={self.gpu_selections})\"\n",
    "\n",
    "\n",
    "def match(key, seq):\n",
    "    i = 0\n",
    "    for k, w in zip(key, seq):\n",
    "        if k != w:\n",
    "            break\n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "\n",
    "class LPRadixCache:\n",
    "    def __init__(self, disable=False):\n",
    "        self.reset()\n",
    "        self.disable = disable\n",
    "\n",
    "    ##### Public API #####\n",
    "\n",
    "    def reset(self):\n",
    "        self.root_node = LPTreeNode()\n",
    "        self.root_node.value = []\n",
    "        self.root_node.ref_counter = 1\n",
    "        self.evictable_size_ = 0\n",
    "\n",
    "    def find_node(self, key):\n",
    "        if self.disable:\n",
    "            return None\n",
    "        current_gpu_selection, node = self.match_prefix_get_gpu_selection(key)\n",
    "        return node\n",
    "\n",
    "    def match_prefix_get_gpu_selection(self, key, path_to_node=[]):\n",
    "        if self.disable:\n",
    "            return [], self.root_node\n",
    "\n",
    "        value = []\n",
    "        current_gpu_selection = self.root_node.gpu_selections\n",
    "        current_gpu_selection, node = self._match_prefix_helper_gpu_selection(\n",
    "            self.root_node, key, value, current_gpu_selection\n",
    "        )\n",
    "        return current_gpu_selection, node\n",
    "\n",
    "    def _match_prefix_helper_gpu_selection(\n",
    "        self, node, key, value, current_gpu_selection\n",
    "    ):\n",
    "        child: LPTreeNode\n",
    "        for c_key, child in node.children.items():\n",
    "            prefix_len = match(c_key, key)\n",
    "            if prefix_len != 0:\n",
    "                if child.gpu_selections:\n",
    "                    current_gpu_selection = child.gpu_selections\n",
    "                if prefix_len < len(c_key):\n",
    "                    print(prefix_len, len(c_key))\n",
    "                    assert False\n",
    "                    new_node = self._split_node(\n",
    "                        c_key, child, prefix_len, new_nodes_created=new_nodes_created\n",
    "                    )\n",
    "                    value.append(new_node.value)\n",
    "                    # last_node[0] = new_node\n",
    "                else:\n",
    "                    value.append(child.value)\n",
    "                    # last_node[0] = child\n",
    "                    return self._match_prefix_helper_gpu_selection(\n",
    "                        child, key[prefix_len:], value, current_gpu_selection\n",
    "                    )\n",
    "        return current_gpu_selection, node\n",
    "\n",
    "    def match_prefix_return_str(self, key):\n",
    "        return \"\".join(self.match_prefix(key)[0])\n",
    "\n",
    "    def insert(\n",
    "        self,\n",
    "        key,\n",
    "        value=None,\n",
    "        node_map=None,\n",
    "        all_modified_nodes=None,\n",
    "        split_nodes=None,\n",
    "        depth_limit=0,\n",
    "    ):\n",
    "        if node_map is None:\n",
    "            node_map = {}\n",
    "        if all_modified_nodes is None:\n",
    "            all_modified_nodes = set()\n",
    "        if split_nodes is None:\n",
    "            split_nodes = {}  # key -> node\n",
    "        if self.disable:\n",
    "            return len(key)\n",
    "\n",
    "        if value is None:\n",
    "            value = [x for x in key]\n",
    "        modified_nodes = set()\n",
    "        created_node = self._insert_helper(\n",
    "            self.root_node,\n",
    "            key,\n",
    "            value,\n",
    "            node_map=node_map,\n",
    "            modified_nodes=modified_nodes,\n",
    "            depth_limit=depth_limit,\n",
    "            current_depth=0,\n",
    "            split_nodes=split_nodes,\n",
    "        )\n",
    "\n",
    "        node: LPTreeNode = created_node\n",
    "        while node is not None:\n",
    "            if node in all_modified_nodes:\n",
    "                break\n",
    "            all_modified_nodes.add(node)\n",
    "            node = node.parent\n",
    "        return created_node\n",
    "\n",
    "    def pretty_print(self):\n",
    "        self._print_helper(self.root_node, 0)\n",
    "        print(f\"#tokens: {self.total_size()}\")\n",
    "\n",
    "    def total_size(self):\n",
    "        return self._total_size_helper(self.root_node)\n",
    "\n",
    "    def evict(self, num_tokens, evict_callback):\n",
    "        if self.disable:\n",
    "            raise RuntimeError()\n",
    "\n",
    "        leaves = self._collect_leaves()\n",
    "        heapq.heapify(leaves)\n",
    "\n",
    "        num_evicted = 0\n",
    "        while num_evicted < num_tokens and len(leaves):\n",
    "            x = heapq.heappop(leaves)\n",
    "\n",
    "            if x == self.root_node:\n",
    "                break\n",
    "            if x.ref_counter > 0:\n",
    "                continue\n",
    "\n",
    "            num_evicted += evict_callback(x)\n",
    "            self._delete_leaf(x)\n",
    "\n",
    "            if len(x.parent.children) == 0:\n",
    "                heapq.heappush(leaves, x.parent)\n",
    "\n",
    "    def smart_evict(self, num_tokens, evict_callback):\n",
    "        if self.disable:\n",
    "            raise RuntimeError()\n",
    "\n",
    "        nodes = self.create_priority_queue()\n",
    "\n",
    "        num_evicted = 0\n",
    "        while num_evicted < num_tokens and len(nodes):\n",
    "            x = heapq.heappop(nodes)\n",
    "\n",
    "            if x == self.root_node:\n",
    "                break\n",
    "\n",
    "            if x.ref_counter > 0:\n",
    "                continue\n",
    "\n",
    "            num_evicted += evict_callback(x)\n",
    "            self._delete_node(x)\n",
    "\n",
    "    def inc_ref_counter(self, node):\n",
    "        delta = 0\n",
    "        while node != self.root_node:\n",
    "            if node.ref_counter == 0:\n",
    "                self.evictable_size_ -= len(node.value)\n",
    "                delta -= len(node.value)\n",
    "            node.ref_counter += 1\n",
    "            node = node.parent\n",
    "        return delta\n",
    "\n",
    "    def dec_ref_counter(self, node):\n",
    "        delta = 0\n",
    "        while node != self.root_node:\n",
    "            # if node.ref_counter == 1: TODO why does this exist?\n",
    "            #     self.evictable_size_ += len(node.value)\n",
    "            #     delta += len(node.value)\n",
    "            node.ref_counter -= 1\n",
    "            node = node.parent\n",
    "        return delta\n",
    "\n",
    "    def remove_completed_input_ids(self, input_ids):\n",
    "        node = self.find_node(input_ids)\n",
    "        self.dec_ref_counter(node)  # remove reference counter up to parent\n",
    "    \n",
    "    def evictable_size(self):\n",
    "        return self.evictable_size_\n",
    "\n",
    "    def _split_node(\n",
    "        self, key, child: LPTreeNode, split_len, node_map, depth_limit, current_depth\n",
    "    ):\n",
    "        # new_node -> child\n",
    "        new_node = LPTreeNode()\n",
    "        new_node.gpu_selections = copy.deepcopy(child.gpu_selections)\n",
    "        new_node.children = {key[split_len:]: child}\n",
    "        new_node.parent = child.parent\n",
    "        new_node.ref_counter = child.ref_counter\n",
    "        new_node.context_length = child.parent.context_length + split_len\n",
    "\n",
    "        new_node.value = child.value[:split_len]\n",
    "        child.parent = new_node\n",
    "        child.value = child.value[split_len:]\n",
    "\n",
    "        new_node.parent.children[key[:split_len]] = new_node\n",
    "        del new_node.parent.children[key]\n",
    "        return new_node\n",
    "\n",
    "    def _insert_helper(\n",
    "        self,\n",
    "        node: LPTreeNode,\n",
    "        key,\n",
    "        value,\n",
    "        node_map,\n",
    "        modified_nodes,\n",
    "        depth_limit,\n",
    "        current_depth,\n",
    "        split_nodes,\n",
    "        parent_context_length = 0\n",
    "    ):\n",
    "        node.last_access_time = time.time()\n",
    "        node.ref_counter += 1\n",
    "\n",
    "        for c_key, child in node.children.items():\n",
    "            prefix_len = match(c_key, key)\n",
    "            if prefix_len == len(c_key):\n",
    "                if prefix_len == len(key):\n",
    "                    child.ref_counter += 1\n",
    "                    modified_nodes.add(child)\n",
    "                    return child\n",
    "                else:\n",
    "                    key = key[prefix_len:]\n",
    "                    value = value[prefix_len:]\n",
    "                    return self._insert_helper(\n",
    "                        child,\n",
    "                        key,\n",
    "                        value,\n",
    "                        node_map=node_map,\n",
    "                        modified_nodes=modified_nodes,\n",
    "                        depth_limit=depth_limit,\n",
    "                        current_depth=current_depth + 1,\n",
    "                        split_nodes=split_nodes,\n",
    "                        parent_context_length=parent_context_length + prefix_len,\n",
    "                    )\n",
    "\n",
    "            if prefix_len:\n",
    "                new_node = self._split_node(\n",
    "                    c_key,\n",
    "                    child,\n",
    "                    prefix_len,\n",
    "                    node_map,\n",
    "                    depth_limit=depth_limit,\n",
    "                    current_depth=current_depth + 1,\n",
    "                )\n",
    "                # modified_nodes.add(new_node)\n",
    "                # modified_nodes.add(child)\n",
    "                # TODO check if this makes sense to ignore this?\n",
    "                # if child in node_map and current_depth < depth_limit:\n",
    "                split_nodes[child] = new_node\n",
    "                return self._insert_helper(\n",
    "                    new_node,\n",
    "                    key[prefix_len:],\n",
    "                    value[prefix_len:],\n",
    "                    node_map=node_map,\n",
    "                    modified_nodes=modified_nodes,\n",
    "                    depth_limit=depth_limit,\n",
    "                    current_depth=current_depth + 1,\n",
    "                    split_nodes=split_nodes,\n",
    "                    parent_context_length=parent_context_length + prefix_len,\n",
    "                )\n",
    "\n",
    "        if len(key):\n",
    "            new_node = LPTreeNode()\n",
    "            new_node.gpu_selections = set()\n",
    "            new_node.parent = node\n",
    "            new_node.value = value\n",
    "            new_node.ref_counter = 1\n",
    "            new_node.context_length = parent_context_length + len(key)\n",
    "\n",
    "            node.children[key] = new_node\n",
    "            self.evictable_size_ += len(value)\n",
    "            # if current_depth < depth_limit:\n",
    "            modified_nodes.add(new_node)\n",
    "            # return new_node\n",
    "            return new_node\n",
    "        return node\n",
    "\n",
    "    def _print_helper(self, node, indent, depth=0):\n",
    "        if depth == 5:\n",
    "            return\n",
    "        for key, child in node.children.items():\n",
    "            print(\" \" * indent, len(key), key[:10], f\"r={child.ref_counter}\")\n",
    "            self._print_helper(child, indent=indent + 2, depth=depth + 1)\n",
    "\n",
    "    def _delete_leaf(self, node):\n",
    "        for k, v in node.parent.children.items():\n",
    "            if v == node:\n",
    "                break\n",
    "        del node.parent.children[k]\n",
    "        self.evictable_size_ -= len(k)\n",
    "\n",
    "    def _delete_node(self, cur_node):\n",
    "        if not cur_node:\n",
    "            return\n",
    "        for child in cur_node.children.values():\n",
    "            self._delete_node(child) # delete all children first\n",
    "        del cur_node.parent.children[cur_node.key]  # Delete the node from its parent's children dictionary\n",
    "        self.evictable_size_ -= len(cur_node.key)  # Adjust evictable size based on the node's key length\n",
    "        # Recursively delete the node's children\n",
    "\n",
    "    def _total_size_helper(self, node):\n",
    "        x = len(node.value)\n",
    "        for child in node.children.values():\n",
    "            x += self._total_size_helper(child)\n",
    "        return x\n",
    "\n",
    "    def _collect_leaves(self):\n",
    "        ret_list = []\n",
    "\n",
    "        def dfs_(cur_node):\n",
    "            if len(cur_node.children) == 0:\n",
    "                ret_list.append(cur_node)\n",
    "\n",
    "            for x in cur_node.children.values():\n",
    "                dfs_(x)\n",
    "\n",
    "        dfs_(self.root_node)\n",
    "        return ret_list\n",
    "\n",
    "    def _collect_nodes(self):\n",
    "        ret_list = []\n",
    "\n",
    "        def dfs_(cur_node):\n",
    "            ret_list.append(cur_node)\n",
    "\n",
    "            for x in cur_node.children.values():\n",
    "                dfs_(x)\n",
    "\n",
    "        dfs_(self.root_node)\n",
    "        return ret_list\n",
    "\n",
    "    def create_priority_queue(self):\n",
    "        nodes = self._collect_nodes()\n",
    "        priority_queue = []\n",
    "        for node in nodes:\n",
    "            if node.ref_count == 0:\n",
    "                priority = node.ref_counter * -1  # Use negative value to simulate a max-heap\n",
    "                heapq.heappush(priority_queue, (priority, node))\n",
    "        return priority_queue\n",
    "\n",
    "class MemSchedulerEvictBasedOnLoad:\n",
    "    def __init__(self, num_nodes=2) -> None:\n",
    "        self.mem_cost = [0 for _ in range(num_nodes)]\n",
    "        self.gpu_allocations = defaultdict(set)\n",
    "        self.num_gpus = num_nodes\n",
    "        self.lock = threading.Lock()\n",
    "        self.cache = LPRadixCache()\n",
    "        self.metrics_dict = []\n",
    "        self.runtime_caches = [LPRadixCache() for _ in range(num_nodes)]\n",
    "        self.max_tokens_gpu = [198516, 198516]\n",
    "        self.counter = 0\n",
    "\n",
    "    def get_recomp_cost(self, node: LPTreeNode, gpu_id):\n",
    "        if not node or gpu_id in node.gpu_selections:\n",
    "            return 0\n",
    "        else:\n",
    "            return node.num_tokens + self.get_recomp_cost(node.parent, gpu_id)\n",
    "\n",
    "    def update_gpu_selections_of_parent(self,node: LPTreeNode, gpu_id):\n",
    "        if not node:\n",
    "            return\n",
    "        node.gpu_selections = node.gpu_selections.union(gpu_id)\n",
    "        self.update_gpu_selections_of_parent(node.parent, gpu_id)\n",
    "\n",
    "    def get_parent_gpu_selections(self, node: LPTreeNode):\n",
    "        if not node:\n",
    "            return set()\n",
    "        if node.gpu_selections:\n",
    "            return node.gpu_selections\n",
    "        return self.get_parent_gpu_selections(node.parent)\n",
    "\n",
    "    def insert_then_evict_from_runtime_cache(self, input_ids, runtime_selected):\n",
    "        runtime_cache = self.runtime_caches[runtime_selected]\n",
    "        node = runtime_cache.insert(tuple(input_ids))\n",
    "        current_max_tokens = self.max_tokens_gpu[runtime_selected]\n",
    "        if runtime_cache.evictable_size() > current_max_tokens:\n",
    "            num_tokens = runtime_cache.evictable_size() - current_max_tokens\n",
    "            runtime_cache.smart_evict(num_tokens, lambda node: self.evict_callback(node, runtime_selected))\n",
    "            print(f\"GPU {runtime_selected} Evictable size: \", runtime_cache.evictable_size(), current_max_tokens)\n",
    "\n",
    "\n",
    "    def evict_callback(self, node: LPTreeNode, runtime_selected: int):\n",
    "        \"\"\"Method to handle eviction logic.\"\"\"\n",
    "        # TODO: Maybe update the parent if child has no parent\n",
    "        num_tokens = len(node.value)\n",
    "        self.mem_cost[runtime_selected] -= num_tokens\n",
    "        return len(node.value)\n",
    "\n",
    "    def runtime_selector(\n",
    "        self,\n",
    "        text: str = None,\n",
    "        request_id: str = None,\n",
    "        input_ids=None,\n",
    "        sampling_params=None\n",
    "    ):\n",
    "        # Tokenize the text\n",
    "        start_time = time.time()\n",
    "        with self.lock:\n",
    "            split_nodes = {}\n",
    "            leaf_node = self.cache.insert(tuple(input_ids), split_nodes=split_nodes)\n",
    "            recom_costs = []\n",
    "            for gpu_id in range(self.num_gpus):\n",
    "                recomputation_cost = self.get_recomp_cost(leaf_node, gpu_id)\n",
    "                recom_costs.append(recomputation_cost)\n",
    "            is_small_node = leaf_node.num_tokens < leaf_node.context_length - leaf_node.num_tokens\n",
    "            if is_small_node:\n",
    "                gpu_selected = self.get_parent_gpu_selections(leaf_node.parent)\n",
    "                assert len(gpu_selected) == 1\n",
    "                runtime_idx = list(gpu_selected)[0]\n",
    "                self.mem_cost[runtime_idx] += recom_costs[runtime_idx]\n",
    "                self.update_gpu_selections_of_parent(leaf_node, {runtime_idx})\n",
    "            else:\n",
    "                cost_f = lambda gpu_id: recom_costs[gpu_id] + self.mem_cost[gpu_id] + leaf_node.num_tokens\n",
    "                gpu_selected = min(range(self.num_gpus), key=cost_f)\n",
    "                gpu_selected = set([gpu_selected])\n",
    "                runtime_idx = list(gpu_selected)[0]\n",
    "                self.mem_cost[runtime_idx] += recom_costs[runtime_idx]\n",
    "                self.update_gpu_selections_of_parent(leaf_node, {runtime_idx})\n",
    "            # self.mem_cost[runtime_idx] += recom_costs[runtime_idx]\n",
    "            # Maybe memory cost should only be updated for the one that gets selected not scheduled\n",
    "            self.counter += 1\n",
    "            self.insert_then_evict_from_runtime_cache(input_ids, runtime_idx)\n",
    "            self.metrics_dict.append(\n",
    "                {\n",
    "                    \"text\": text[:100],\n",
    "                    \"rid\": request_id,\n",
    "                    \"selected_runtime\": runtime_idx,\n",
    "                    \"overhead\": time.time() - start_time,\n",
    "                    \"mem_costs\": self.mem_cost,\n",
    "                    \"parent_memory_cost\": self.get_recomp_cost(leaf_node.parent, runtime_idx),\n",
    "                    \"current_leaf_node_cost\": leaf_node.num_tokens,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            return int(runtime_idx)\n",
    "\n",
    "    def finish_request(\n",
    "        self, text: str = None, request_id: str = None, input_ids=None, func_output: RequestFuncOutput=None\n",
    "    ):\n",
    "        with self.lock:\n",
    "            self.cache.remove_completed_input_ids(input_ids)\n",
    "            self.runtime_caches[func_output.runtime_selected].remove_completed_input_ids(input_ids)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
